{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebc9ff-5a86-4314-870c-011ff4ddae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lmdb\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "import kornia.augmentation as K\n",
    "\n",
    "from cvtorchvision import cvtransforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from PIL import ImageFilter\n",
    "import random\n",
    "import cv2\n",
    "from argparse import Namespace\n",
    "from pretrain_ssl.datasets.SSL4EO.ssl4eo_dataset_lmdb import LMDBDataset\n",
    "from pretrain_ssl.datasets.SSL4EO.ssl4eo_dataset import SSL4EO\n",
    "\n",
    "### band statistics: mean & std\n",
    "# calculated from 50k subset\n",
    "S1_MEAN = [-12.54847273, -20.19237134]\n",
    "S1_STD = [5.25697717, 5.91150917]\n",
    "\n",
    "S2A_MEAN = [752.40087073, 884.29673756, 1144.16202635, 1297.47289228, 1624.90992062, 2194.6423161, 2422.21248945, 2517.76053101, 2581.64687018, 2645.51888987, 2368.51236873, 1805.06846033]\n",
    "S2A_STD = [1108.02887453, 1155.15170768, 1183.6292542, 1368.11351514, 1370.265037, 1355.55390699, 1416.51487101, 1474.78900051, 1439.3086061, 1582.28010962, 1455.52084939, 1343.48379601]\n",
    "\n",
    "S2C_MEAN = [1605.57504906, 1390.78157673, 1314.8729939, 1363.52445545, 1549.44374991, 2091.74883118, 2371.7172463, 2299.90463006, 2560.29504086, 830.06605044, 22.10351321, 2177.07172323, 1524.06546312]\n",
    "S2C_STD = [786.78685367, 850.34818441, 875.06484736, 1138.84957046, 1122.17775652, 1161.59187054, 1274.39184232, 1248.42891965, 1345.52684884, 577.31607053, 51.15431158, 1336.09932639, 1136.53823676]\n",
    "\n",
    "ALL_BANDS_S2_L2A = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\n",
    "ALL_BANDS_S2_L1C = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B10', 'B11', 'B12']\n",
    "RGB_BANDS = ['B4', 'B3', 'B2']\n",
    "ALL_BANDS_S1_GRD = ['VV', 'VH']\n",
    "\n",
    "def normalize(img, mean, std):\n",
    "    \"\"\"\n",
    "    Normalize a single-channel Numpy array [H,W].\n",
    "    Input is unbounded float32, output is uint8 in range [0, 255].\n",
    "    \"\"\"\n",
    "    min_value = mean - 2 * std\n",
    "    max_value = mean + 2 * std\n",
    "    img = (img - min_value) / (max_value - min_value) * 255.0\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def normalize_img(img, means, stds):\n",
    "    \"\"\"\n",
    "    Normalize Numpy array of shape [C,H,W].\n",
    "    Input is unbounded float32, output is uint8 in range [0, 255].\n",
    "    \"\"\"\n",
    "    if type(means) is list:\n",
    "        means = np.array(means)\n",
    "    if type(stds) is list:\n",
    "        stds = np.array(stds)\n",
    "        \n",
    "    min_values = (means - 2 * stds)[:, None, None]  # add extra dimensions to make broadcasting work\n",
    "    max_values = (means + 2 * stds)[:, None, None]\n",
    "    img = (img - min_values) / (max_values - min_values) * 255.0\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def denormalize_img(img, means, stds):\n",
    "    \"\"\"\n",
    "    Converts a normalized uint8 Numpy array in the range [0, 255] into a \n",
    "    denormalized float32 Numpy array, with raw intensity values from Sentinel\n",
    "    (divided by 10000 and clipped to [0, 1]).\n",
    "\n",
    "    The input is assumed to have been normalized by the 'normalize' method for each\n",
    "    channel, with the given mean/std.\n",
    "\n",
    "    Input and output should have shape [C, H, W].\n",
    "    \"\"\"\n",
    "    if type(means) is list:\n",
    "        means = np.array(means)\n",
    "    if type(stds) is list:\n",
    "        stds = np.array(stds)\n",
    "\n",
    "    min_values = (means - 2 * stds)[:, None, None]  # add extra dimensions to make broadcasting work\n",
    "    max_values = (means + 2 * stds)[:, None, None]\n",
    "    denormalized_img = (img.astype(np.float32) / 255.0) * (max_values - min_values) + min_values\n",
    "    denormalized_img = np.clip(denormalized_img / 10000.0, 0, 1)\n",
    "    return denormalized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f73828-b627-4b21-b5c4-051355320650",
   "metadata": {},
   "source": [
    "## Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746e214-1309-49cf-a8bf-d14af97fb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.dtype=='uint8':\n",
    "#     from models.rs_transforms_uint8 import RandomChannelDrop,RandomBrightness,RandomContrast,ToGray\n",
    "# else:\n",
    "from pretrain_ssl.models.rs_transforms_float32 import RandomChannelDrop,RandomBrightness,RandomContrast,ToGray\n",
    "    \n",
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, season='fixed'):\n",
    "        self.base_transform = base_transform\n",
    "        self.season = season\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        if self.season=='augment':\n",
    "            season1 = np.random.choice([0,1,2,3])\n",
    "            season2 = np.random.choice([0,1,2,3])\n",
    "        elif self.season=='fixed':\n",
    "            np.random.seed(42)\n",
    "            season1 = np.random.choice([0,1,2,3])\n",
    "            season2 = season1\n",
    "        elif self.season=='random':\n",
    "            season1 = np.random.choice([0,1,2,3])\n",
    "            season2 = season1\n",
    "\n",
    "        x1 = np.transpose(x[season1,:,:,:],(1,2,0))\n",
    "        x2 = np.transpose(x[season2,:,:,:],(1,2,0))\n",
    "\n",
    "        q = self.base_transform(x1)\n",
    "        k = self.base_transform(x2)\n",
    "\n",
    "        return [q, k]\n",
    "\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[.1, 2.]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        #x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        #return x\n",
    "        return cv2.GaussianBlur(x,(0,0),sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbfb9bd-1f2e-48f3-81dd-cebdc7d3027d",
   "metadata": {},
   "source": [
    "## Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc379b-37b7-43db-aad0-ff1f91ca19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img, rgb_bands=[3, 2, 1], band_names=None, row_label=None):\n",
    "    \"\"\"\n",
    "    Plot the given img, assumed to be a Numpy array or Tensor of shape\n",
    "    [C, H, W], with pixel values between [0, 1]. The output will be a row\n",
    "    of images: an RGB image (if rgb_bands provided), then an image for each band.\n",
    "\n",
    "    \"band_names\" should be a list of length C, with the name\n",
    "    of each band (for the header). If None, do not produce a header.\n",
    "\n",
    "    \"row_label\" is a label for the row (optional)\n",
    "    \"\"\"\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.detach().cpu().numpy()\n",
    "\n",
    "    # If image is uint8, rescale it to be in [0, 1]\n",
    "    if img.dtype == np.uint8:\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    if band_names is not None:\n",
    "        assert len(band_names) == img.shape[0]\n",
    "    n_cols = img.shape[0]\n",
    "    if rgb_bands is not None:\n",
    "        n_cols += 1\n",
    "\n",
    "    # Create row of images\n",
    "    fig, axeslist = plt.subplots(1, n_cols, figsize=(n_cols*3, 3))\n",
    "\n",
    "    # Row label\n",
    "    if row_label is not None:\n",
    "        axeslist[0].set_ylabel(row_label, size=14)\n",
    "\n",
    "    # Image of each band\n",
    "    for i in range(img.shape[0]):\n",
    "        band_img = img[i, :, :] # [H, W]\n",
    "        axeslist[i].imshow(band_img, vmin=0, vmax=1)\n",
    "        axeslist[i].set_axis_off()  # Remove axis ticks\n",
    "        if band_names is not None:\n",
    "            axeslist[i].set_title(band_names[i])\n",
    "\n",
    "    # RGB image\n",
    "    if rgb_bands is not None:\n",
    "        rgb_img = img[rgb_bands, :, :].transpose((1, 2, 0))  # Transpose to [H, W, C]\n",
    "        axeslist[-1].imshow(rgb_img)\n",
    "        axeslist[-1].set_axis_off()  # Remove axis ticks\n",
    "        if band_names is not None:\n",
    "            axeslist[-1].set_title(\"RGB\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_histogram(ax, values, title):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the given 'values' to 'ax'. The title contains the 'title' string\n",
    "    (along with mean/std/min/max)\n",
    "    \"\"\"\n",
    "    ax.hist(values, bins=30)\n",
    "    ax.set_title(\"{}:\\nmean={:.2f}, std={:.2f}\\nmin={:.2f}, max={:.2f}\\np1={:.2f}, p99={:.2f}\".format(\n",
    "                 title, np.mean(values), np.std(values), np.min(values), np.max(values),\n",
    "                 np.quantile(values, 0.01), np.quantile(values, 0.99)))\n",
    "\n",
    "\n",
    "def plot_histogram_all_channels(imgs, band_names=None):\n",
    "    \"\"\"\n",
    "    Plots the distribution of each channel in the given images.\n",
    "\n",
    "    'imgs' is a Numpy array of images, shape [B, C, H, W]\n",
    "    band_names is a list of channel names, length C.\n",
    "    \"\"\"\n",
    "    if band_names is None:\n",
    "        band_names = [f\"Channel {i}\" for i in range(imgs.shape[1])]\n",
    "\n",
    "    nrows = math.ceil(len(band_names) / 4)\n",
    "    ncols = 4\n",
    "    fig, axeslist = plt.subplots(nrows, ncols, figsize=(3*ncols, 3*nrows))\n",
    "\n",
    "    # Loop through each band\n",
    "    for band_idx, band_name in enumerate(band_names):\n",
    "        vals = imgs[:, band_idx, :, :].flatten()\n",
    "        plot_histogram(axeslist.ravel()[band_idx], vals, band_name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_batch(imgs, rgb_bands=[3, 2, 1], band_names=None):\n",
    "    \"\"\"\n",
    "    Takes a batch of images (Tensor or Numpy), of shape [B, C, H, W].\n",
    "    Produces a histogram of pixel values for each channel, and displays a few sample images.\n",
    "    \"\"\"\n",
    "    print(\"Imgs shape\", imgs.shape, imgs.dtype, type(imgs))\n",
    "    if isinstance(imgs, torch.Tensor):\n",
    "        imgs = imgs.detach().cpu().numpy()\n",
    "\n",
    "    plot_histogram_all_channels(imgs, band_names)\n",
    "    for idx in range(3):\n",
    "        plot_img(imgs[idx, :, :, :], rgb_bands=rgb_bands, band_names=band_names, row_label=f\"Image {idx}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443f8f8-1b37-431c-bc32-4e9e63c23684",
   "metadata": {},
   "source": [
    "## SSL4EO images (raw uint8, not LMDB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27102e9a-ae8a-4176-ba47-55875bea293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw images, without normalizing.\n",
    "args = Namespace()\n",
    "args.root = \"/mnt/beegfs/bulk/mirror/jyf6/datasets/SSL4EO_data/0k_251k_uint8_jpeg_tif\"\n",
    "args.normalize = False\n",
    "args.mode = [\"s2c\"]\n",
    "args.dtype = \"uint8\"\n",
    "\n",
    "train_dataset = SSL4EO(root=args.root, normalize=args.normalize, mode=args.mode, dtype=args.dtype)\n",
    "\n",
    "# Get a batch of images\n",
    "imgs = []\n",
    "for idx in np.random.choice(len(train_dataset), 16):\n",
    "    # s2c is a numpy array of shape [T, C, H, W], uint8\n",
    "    s1, s2a, s2c = train_dataset[idx]\n",
    "    imgs.append(s2c)\n",
    "imgs = np.concatenate(imgs, axis=0)\n",
    "\n",
    "# Plot the images\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L1C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb678447-f33b-4d58-9d4a-38a0ffbab6e7",
   "metadata": {},
   "source": [
    "## SSL4EO images, LMDB (no transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62de9fc-3978-40b3-99a4-97610d4d626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LMDBDataset with transforms\n",
    "train_dataset_raw = LMDBDataset(\n",
    "    lmdb_file='/mnt/beegfs/bulk/mirror/jyf6/datasets/SSL4EO_data/0k_251k_uint8_jpeg_tif/ssl4eo_251k_s2c_uint8.lmdb',\n",
    "    s2c_transform=None,\n",
    "    is_slurm_job=False,\n",
    "    normalize=False,\n",
    "    mode = ['s2c'],\n",
    "    dtype='uint8'\n",
    ")\n",
    "\n",
    "# Plot images directly from the dataset (__getitem__)\n",
    "imgs = []\n",
    "for idx in np.random.choice(len(train_dataset_raw), 16):\n",
    "    # NUMPY array of shape [T, C, H, W]. DENORMALIZED from [0, 255] to the raw S2 values, divided by 10000\n",
    "    s2c = train_dataset_raw[idx]\n",
    "    print(s2c.shape, s2c.dtype)\n",
    "    imgs.append(s2c)\n",
    "imgs = np.concatenate(imgs, axis=0)\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L1C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc83d7ea-1ac2-4596-af3f-e8afa623cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images from the dataloader\n",
    "train_loader_raw = torch.utils.data.DataLoader(train_dataset_raw, batch_size=32, shuffle=False)\n",
    "imgs = next(iter(train_loader_raw))  # Batch from dataloader: [B, T, C, H, W]\n",
    "imgs = imgs.reshape((-1, imgs.shape[2], imgs.shape[3], imgs.shape[4]))  # [B*T, C, H, W]\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L1C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff75da9-92aa-4007-8424-0e25fe7fdd82",
   "metadata": {},
   "source": [
    "## Contrastive SSL4EO dataset (LMDB). Augmented views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5eb5d-d9f9-4611-9a82-bef18a6d8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentations\n",
    "train_transforms_s1 = cvtransforms.Compose([\n",
    "    cvtransforms.RandomResizedCrop(112, scale=(0.2, 1.)),\n",
    "    cvtransforms.RandomApply([\n",
    "        RandomBrightness(0.4),\n",
    "        RandomContrast(0.4)\n",
    "    ], p=0.8),\n",
    "    cvtransforms.RandomApply([ToGray(2)], p=0.2),\n",
    "    cvtransforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "    cvtransforms.RandomHorizontalFlip(),\n",
    "    #cvtransforms.RandomApply([RandomChannelDrop(min_n_drop=1, max_n_drop=6)], p=0.5),        \n",
    "    cvtransforms.ToTensor()\n",
    "])\n",
    "train_transforms_s2a = cvtransforms.Compose([\n",
    "    cvtransforms.RandomResizedCrop(112, scale=(0.2, 1.)),\n",
    "    cvtransforms.RandomApply([\n",
    "        RandomBrightness(0.4),\n",
    "        RandomContrast(0.4)\n",
    "    ], p=0.8),\n",
    "    cvtransforms.RandomApply([ToGray(12)], p=0.2),\n",
    "    cvtransforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "    cvtransforms.RandomHorizontalFlip(),\n",
    "    cvtransforms.RandomApply([RandomChannelDrop(min_n_drop=1, max_n_drop=6)], p=0.5),        \n",
    "    cvtransforms.ToTensor()\n",
    "])\n",
    "train_transforms_s2c = cvtransforms.Compose([\n",
    "    cvtransforms.RandomResizedCrop(112, scale=(0.2, 1.)),\n",
    "    cvtransforms.RandomApply([\n",
    "        RandomBrightness(0.4),\n",
    "        RandomContrast(0.4)\n",
    "    ], p=0.8),\n",
    "    cvtransforms.RandomApply([ToGray(13)], p=0.2),\n",
    "    cvtransforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "    cvtransforms.RandomHorizontalFlip(),\n",
    "    cvtransforms.RandomApply([RandomChannelDrop(min_n_drop=1, max_n_drop=6)], p=0.5),        \n",
    "    cvtransforms.ToTensor()\n",
    "])\n",
    "\n",
    "# LMDB data with TwoCropsTransform (actually used)\n",
    "train_dataset = LMDBDataset(\n",
    "    lmdb_file='/mnt/beegfs/bulk/mirror/jyf6/datasets/SSL4EO_data/0k_251k_uint8_jpeg_tif/ssl4eo_251k_s2c_uint8.lmdb',\n",
    "    # s1_transform=TwoCropsTransform(train_transforms_s1,season='augment'),\n",
    "    # s2a_transform=TwoCropsTransform(train_transforms_s2a,season='augment'),\n",
    "    s2c_transform=TwoCropsTransform(train_transforms_s2c,season='augment'),\n",
    "    is_slurm_job=False,\n",
    "    normalize=False,\n",
    "    mode = ['s2c'],\n",
    "    dtype='uint8'\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "view0, view1 = next(iter(train_loader))  # view0, view1 are float32 Tensor [B, C, H, W]\n",
    "plot_batch(view0, band_names=ALL_BANDS_S2_L1C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de0093-784b-40e9-bbd2-9e92214ab58b",
   "metadata": {},
   "source": [
    "## BigEarthNet dataset (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d53b89-06f1-4203-8750-38859b2f59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer_classification.datasets.BigEarthNet.bigearthnet_dataset_seco import Bigearthnet\n",
    "\n",
    "args = Namespace()\n",
    "args.data_dir = \"/mnt/beegfs/bulk/mirror/jyf6/datasets/geospatial/datasets/BigEarthNet\"\n",
    "all_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "args.download = False\n",
    "train_dataset = Bigearthnet(\n",
    "    root=args.data_dir,\n",
    "    split='train',\n",
    "    bands=all_bands,\n",
    "    download=args.download,\n",
    "    normalize=False,\n",
    ")\n",
    "\n",
    "# Get a batch of images (directly from __getitem__)\n",
    "imgs = []\n",
    "for idx in np.random.choice(len(train_dataset), 16):\n",
    "    img, target = train_dataset[idx]  # img: Numpy int16, [H, W, C]  Target: binary vector (multi-hot)\n",
    "    img = img.transpose((2, 0, 1)).astype(np.float32)\n",
    "    img = np.clip(img / 10000.0, 0, 1)  # Numpy float32, [C, H, W]\n",
    "    imgs.append(img)\n",
    "imgs = np.stack(imgs, axis=0)  # [B, C, H, W]\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L2A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ddd5b2-1f84-49f7-bb8c-809999c38bca",
   "metadata": {},
   "source": [
    "## BigEarthNet dataset (LMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd2b722-489e-452f-981c-a7432b83ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transfer_classification.datasets.BigEarthNet.bigearthnet_dataset_seco_lmdb_s2_uint8 import LMDBDataset\n",
    "\n",
    "train_transforms = cvtransforms.Compose([\n",
    "    cvtransforms.RandomResizedCrop(224,scale=(0.8,1.0)), # multilabel, avoid cropping out labels\n",
    "    cvtransforms.RandomHorizontalFlip(),\n",
    "    cvtransforms.ToTensor()])\n",
    "train_dataset = LMDBDataset(\n",
    "    lmdb_file=os.path.join(args.data_dir, \"train_B12.lmdb\"),\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "# Get images directly from Dataset\n",
    "imgs = []\n",
    "for idx in np.random.choice(len(train_dataset), 16):\n",
    "    img, target = train_dataset[idx]  # Tensor [channel, height, width], unnormalized divided by 10000 (float32)\n",
    "    imgs.append(img)\n",
    "imgs = torch.stack(imgs, axis=0)  # [batch, channel, height, width]\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L2A) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae616fc1-f02a-4f41-a55f-cd242d61cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images from Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "imgs, target = next(iter(train_loader))\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L2A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bb8fe-48fb-4edb-891f-8d924e40203c",
   "metadata": {},
   "source": [
    "## EuroSAT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6494733-6bd3-493c-a044-e61f849bf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer_classification.datasets.EuroSat.eurosat_dataset import EurosatDataset, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cvtorchvision import cvtransforms\n",
    "\n",
    "args = Namespace()\n",
    "args.data_dir = \"/mnt/beegfs/bulk/mirror/jyf6/datasets/geospatial/datasets/EuroSAT_MS\"\n",
    "args.bands = \"B13\"\n",
    "args.seed = 42\n",
    "eurosat_dataset = EurosatDataset(root=args.data_dir,bands=args.bands, normalize=False)\n",
    "\n",
    "train_transforms = cvtransforms.Compose([\n",
    "        cvtransforms.RandomResizedCrop(224),\n",
    "        #cvtransforms.Resize(args.in_size),\n",
    "        cvtransforms.RandomHorizontalFlip(),\n",
    "        cvtransforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "val_transforms = cvtransforms.Compose([\n",
    "        cvtransforms.Resize(256),\n",
    "        cvtransforms.CenterCrop(224),\n",
    "        cvtransforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "# Split into train/val\n",
    "indices = np.arange(len(eurosat_dataset))\n",
    "train_indices, test_indices = train_test_split(indices, train_size=0.8,stratify=eurosat_dataset.targets,random_state=args.seed)    \n",
    "train_dataset = Subset(eurosat_dataset, train_indices, train_transforms)\n",
    "val_dataset = Subset(eurosat_dataset, test_indices, val_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "imgs, target = next(iter(train_loader))\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L1C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e30197-ff36-4b09-a173-201a84d761bf",
   "metadata": {},
   "source": [
    "## SustainBench-BigEarthNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e92b0-d300-4a23-b422-1fee7061884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../geo_benchhmarks\")\n",
    "from geo_benchhmarks.test import get_data_loaders\n",
    "\n",
    "# Augmentations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # Random horizontal flip\n",
    "    transforms.RandomVerticalFlip(), # Random vertical flip\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1]\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders(\"bigearthnet\", train_transform=train_transform, test_transform=test_transform)\n",
    "imgs = next(iter(train_loader))\n",
    "print(\"Imgs shape\", imgs.shape, imgs.dtype)\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L2A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93b9b0-e07b-4dea-ab10-f2c409c32e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_data_loaders(\"brick-kiln\", train_transform=train_transform, test_transform=test_transform)\n",
    "imgs = next(iter(train_loader))\n",
    "print(\"Imgs shape\", imgs.shape, imgs.dtype)\n",
    "plot_batch(imgs, band_names=ALL_BANDS_S2_L2C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de093c-a002-441a-ac24-8091ca3bde3d",
   "metadata": {},
   "source": [
    "## ShapeContrast dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e5742-92bc-43e7-b906-0f024bfe0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.rs_transforms_kornia import RandomChannelDrop,RandomBrightness,RandomContrast,ToGray\n",
    "\n",
    "class ShapeColorTransform:\n",
    "    \"\"\"Take three crops of one image:\n",
    "    V1 = base_transform(img)\n",
    "    V2 = intensity_transform(base_transform(img))\n",
    "    V3 = geometric_transform(base_transform(img))\n",
    "\n",
    "    V2 is the \"shape key\" (similar shape but with different color),\n",
    "    V3 is the \"color key\" (similar color but geometric transform).\n",
    "    All get passed through 'base_transform.\n",
    "    If `season` is `augment`, changing seasons counts as an intensity transform.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, intensity_transform, geometric_transform, season='fixed'):\n",
    "        self.base_transform = base_transform\n",
    "        self.intensity_transform = intensity_transform\n",
    "        self.geometric_transform = geometric_transform\n",
    "        self.season = season\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.season=='augment':\n",
    "            season1 = np.random.choice([0,1,2,3])\n",
    "            season2 = np.random.choice([0,1,2,3])\n",
    "        elif self.season=='fixed':\n",
    "            np.random.seed(42)\n",
    "            season1 = np.random.choice([0,1,2,3])\n",
    "            season2 = season1\n",
    "        elif self.season=='random':\n",
    "            season1 = np.random.choice([0,1,2,3])\n",
    "            season2 = season1\n",
    "\n",
    "        x1 = torch.tensor(x[season1,:,:,:])  # @joshuafan: For kornia, there is no need to transpose. We keep the order of [C, H, W].\n",
    "        x2 = torch.tensor(x[season2,:,:,:])\n",
    "        # print(\"At start of ShapeColorTransform\", x1.shape, x2.shape)\n",
    "\n",
    "        v1 = self.base_transform(x1).squeeze(0)  # Kornia adds a batch dimension (1) at the beginning. We can remove it.\n",
    "        v2 = self.intensity_transform(self.base_transform(x2)).squeeze(0)\n",
    "        v3 = self.geometric_transform(self.base_transform(x1)).squeeze(0)\n",
    "        # print(\"After ShapeColorTransform, views:\", v1.shape, v2.shape, v3.shape)\n",
    "        return [v1, v2, v3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35242f56-7fd1-4dd4-ac87-3f26271a485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transform = K.RandomResizedCrop(size=(112, 112), scale=(0.2, 1.), p=1)\n",
    "intensity_transforms = [RandomBrightness(0.4, p=0.8),\n",
    "                        RandomContrast(0.4, p=0.8),\n",
    "                        ToGray(13, p=0.2),\n",
    "                        RandomChannelDrop(min_n_drop=1, max_n_drop=6, p=0.5)]\n",
    "intensity_transform = K.AugmentationSequential(*intensity_transforms, data_keys=[\"input\"])\n",
    "geometric_transforms = [K.RandomHorizontalFlip(p=0.5),\n",
    "                        K.RandomVerticalFlip(p=0.5),\n",
    "                        K.RandomGaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0), p=0.5),\n",
    "                        K.RandomJigsaw(grid=(16,16), p=0.8)]\n",
    "geometric_transform = K.AugmentationSequential(*geometric_transforms, data_keys=[\"input\"])\n",
    "\n",
    "train_dataset = LMDBDataset(\n",
    "    lmdb_file='/mnt/beegfs/bulk/mirror/jyf6/datasets/geospatial/datasets/SSL4EO/0k_251k_uint8_jpeg_tif/ssl4eo_251k_s2c_uint8.lmdb',\n",
    "    s2c_transform=ShapeColorTransform(base_transform, intensity_transform, geometric_transform, season='augment'),\n",
    "    is_slurm_job=False,\n",
    "    normalize = False,\n",
    "    mode = ['s2c'],\n",
    "    dtype='uint8'\n",
    ")\n",
    "\n",
    "train_dataset_raw = LMDBDataset(\n",
    "    lmdb_file='/mnt/beegfs/bulk/mirror/jyf6/datasets/geospatial/datasets/SSL4EO/0k_251k_uint8_jpeg_tif/ssl4eo_251k_s2c_uint8.lmdb',\n",
    "    s2c_transform=None,\n",
    "    is_slurm_job=False,\n",
    "    normalize = False,\n",
    "    mode = ['s2c'],\n",
    "    dtype='uint8'\n",
    ")\n",
    "\n",
    "# Get images directly from the dataset __getitem__ method\n",
    "for idx in [1]:\n",
    "    s2c_orig = train_dataset_raw[idx]  # [season, channel, height, width]\n",
    "    print(s2c_orig.shape)  \n",
    "    plot_img(s2c_orig[0, :, :, :], band_names=ALL_BANDS_S2_L1C, rgb_bands=[3,2,1], row_label=f\"Raw image\")\n",
    "\n",
    "    # Print example values\n",
    "    s2c_views = train_dataset[idx]  # list of [channel, height, width]\n",
    "    for view_idx in range(3):\n",
    "        # print(s2c_views[view_idx].shape)\n",
    "        plot_img(s2c_views[view_idx][:, :, :], band_names=ALL_BANDS_S2_L1C, rgb_bands=[3,2,1], row_label=f\"View {view_idx} S2C\")\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, num_workers=0, shuffle=False)\n",
    "# train_loader_raw = torch.utils.data.DataLoader(train_dataset, batch_size=4, num_workers=0, shuffle=False)\n",
    "# for idx, s2c in enumerate(train_loader):\n",
    "#     if idx>0:\n",
    "#         break\n",
    "#     print(s2c[0].shape)\n",
    "\n",
    "#     # Print example values\n",
    "#     for view_idx in range(3):\n",
    "#         plot_img(s2c[view_idx][0, :, :, :], band_names=ALL_BANDS_S2_L1C, rgb_bands=[3,2,1], row_label=f\"View {view_idx} S2C\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1fe2f-f9d4-4a83-b672-9cd373c4af3f",
   "metadata": {},
   "source": [
    "## Brickkiln dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36bda82-c55b-4239-80c1-92dcb421bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../geo_benchhmarks\")\n",
    "from ssl_main import GeoBenchDataSet\n",
    "\n",
    "data_set_name = \"brick-kiln\"\n",
    "args.bands = \"B13\"\n",
    "train_supervised_ds = GeoBenchDataSet(dataset_name=data_set_name,split=\"train\",sl_split=\"sl\", transforms=train_transform, bands=args.bands)\n",
    "test_ds = GeoBenchDataSet(dataset_name=data_set_name,split=\"test\", transforms=test_transform, bands=args.bands)\n",
    "\n",
    "# Now put as torch data loaders \n",
    "train_supervised_loader = torch.utils.data.DataLoader(train_supervised_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ff02b-1691-4323-8c3c-740cb549190d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8b862-078c-4d25-a84f-1067859012b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b5480-1ff7-4d15-824a-9b7a11af208b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ef2ff-fda0-4c44-956b-a09d96560fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
